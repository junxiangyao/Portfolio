

<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="author" content="Junxiang Yao">
    <meta name="description" content="Digitalizing the coffee chats between students and professionals">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Flocking around Water</title>
    <link rel="shortcut icon" href="img/LOGO.png"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha512-NhSC1YmyruXifcj/KFRWoC561YpHpc5Jtzgvbuzx5VozKpWvQ+4nXhPdFgmx8xqexRcpAglTj9sIBWINXa8x5w==" crossorigin="anonymous" />
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link rel="stylesheet" type="text/css" href="css/casestudy.css">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;0,800;1,300;1,400;1,600;1,700;1,800&display=swap" rel="stylesheet">
  </head>

<body>
  <header>
    <div class="container">
      <div class="logo">
        <a href="index.html"> <img src="img/LOGO.png" alt="" style="max-width:32px; display:block"></a>
      </div>
      <nav>
        <ul class="">
          <li><a href="index.html">Work</a></li>
          <li><a href="about.html">About</a></li>
          <li><a href="#contact">Contact</a></li>
        
        </ul>
      </nav>
    </div>
  </header>

  <main>
  </main>


  <div class="introduction case-study-container">
    <div class="title-expl" style="margin-bottom:30px;text-align:center">
        <h2>Flocking around Water</h2>
        <h5>Mar. 2017</h5>
        <br>
    </div>
    <hr>
  </div>



	<div class="container">
		<div class="introduction">
			<h4>Introduction</h4>
			<p>
				Flocking around Water is a interactive project built in <a href="http://www.allosphere.ucsb.edu">AlloSphere</a>,
				a large-scale facility which creates an immersive environment inside. This project is an audio visual composition that 3 groups of sound generating agents flock inside the environment and interact with the user.
				The goal of this project is to design an immersive user interface system that intended to blur the boundary between user interface components that is not included in the content of the scene and the virtual objects in the scene.
				Three groups of flocking objects were not only the components of the visual animation but also the controllers that control the flocking animation and the surrounding sounds respectively. This project is the final project for MAT 201B, Computing with Media Data, at UCSB.

			 </p>

			<p><span class="accentuate"> Advisor:</span> Karl Yerkes</p>
			<p>
			 	<span class="accentuate"> Programming Language:</span>  C++
			 </p>
			<p><span class="accentuate"> Tools:</span> AlloSphere, PhaseSpace Gloves</p>
			<p><span class="accentuate"> Exhibition:</span> MAT End of Year Show 2017, UCSB
		</div>

		<div class="information">

		</div>

		<div class="discription">
			<div class="projectImage">
				<img src="flockingAroundWater/10.jpg">
			</div>
			<p>
				This piece in AlloSphere creates a virtual world containing 3 groups of agents flocking inside. The flocking behavior, color and sound of each group is different from each other. The purplish cones are generating the sound of filtered closed hi-hat, the greenish cubes are generating chirping sound from crickets, and the small yellow tetrahedrons, which are representing "water" in this scenario is moving around with the sound of a running brook. The center of each group, which is their average position in the space, will be used as the sound source position for spatial sound.
				<br>
				<br>
				The interaction is realized by a pair of gloves, which were PhaseSpace Gloves modified by Tim Wood from AlloSphere research group to make it fully functional in AlloSphere. By pinching with the left index finger and the left thumb towards an agent, that agent will be picked, and all the other akin agents will stop their flocking behavior to seek the position of the picked one. And the picked one will follow the movemont of the left hand after being captured, followed by the whole group. By pinching with the right index finger and the right thumb after that, the picked agent and its group will be dragged closer to the center of the Allosphere, which will increase the amplitude of the sound from this group.
			</p>
			<div class="projectImage">
				<img src="flockingAroundWater/2.jpg">
			</div>
			<div class="projectImage">
				<img src="flockingAroundWater/3.jpg">
			</div>
			<p>
				Try to catch an agent.
			</p>
			<div class="projectImage">
				<img src="flockingAroundWater/4.jpg">
			</div>
			<p>
				Captured a cone, and dragged towords the center of the AlloSphere, result in an amplified sound effect and the whole cone group is crowded around the operator and the audience.
			</p>
			<div class="projectImage">
				<img src="flockingAroundWater/5.jpg">
			</div>
			<p>
				Unleash the whole group.
			</p>
			<div class="projectImage">
				<img src="flockingAroundWater/6.jpg">
			</div>
			<div class="projectImage">
				<img src="flockingAroundWater/7.jpg">
			</div>
			<p>
				Captured the cone group again and dragged them around inside the virtual world.
			</p>
			<div class="projectImage">
				<img src="flockingAroundWater/8.jpg">
			</div>
			<div class="projectImage">
				<img src="flockingAroundWater/9.jpg">
			</div>
			<div class="projectImage">
				<img src="flockingAroundWater/1.jpg">
			</div>
			<div class="projectImage">
				<img src="flockingAroundWater/11.jpg">
			</div>
			<div class="projectImage">
				<img src="flockingAroundWater/12.jpg">
			</div>
			<p>
				Because the stereoscopic effect in the AlloSphere is realized by 26 projectors, which are connecting to one simulator, projecting on the sphere-shaped "wall" inside it, the viewer will need to wear a pair of special-made glasses to see the three-dimensional scenes. Thus, it is almost impossible to record a video of the project in the AlloSphere and show the same effect when play it on a regular computer screen afterwards. To somewhat depict how this project works, I recorded two videos of this piece running on my own computer.

			<div>
				<div class='embed-container'>
					<iframe style="width:100%" src="https://player.vimeo.com/video/239351917" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
				</div>
				<br>
				<em>Outside view.</em>
			</div>
			<div>
				<div class='embed-container'>
					<iframe style="width:100%" src="https://player.vimeo.com/video/239396144" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
				</div>
				<br>
				<em>Inside view.</em>
			</div>
			<br>
			<br>
			<br>

			<hr>

			<br>
			<br>
			<br>
			<!-- * * * * * * * * * * * * * * * * * * * * * * *

				filters

			* * * * * * * * * * * * * * * * * * * * * * * * -->
			<div id="filters_mix"></div>
			<div id="content_container"></div>
			<script src="https://unpkg.com/react@16/umd/react.development.js" crossorigin></script>
			<script src="https://unpkg.com/react-dom@16/umd/react-dom.development.js" crossorigin></script>
			<script src="../content_projects.js"></script>
		</div>
	</div>
	<br>
	<br>
	<br>
	<!-- <hr>	 -->





</body>
</html>
